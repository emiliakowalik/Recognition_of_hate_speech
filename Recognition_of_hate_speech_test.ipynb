{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQd1ahvNz82chr06R+OQNF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "import string\n",
        "import pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHDWabULym1i",
        "outputId": "f746f6b4-d0ea-4a55-b3ae-00b450eb78f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "  cleaned = ''.join([word for word in text if word not in string.punctuation])\n",
        "  return cleaned"
      ],
      "metadata": {
        "id": "p2iuWvZv5QXp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RemovePunctuationTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, text_column):\n",
        "        self.text_column = text_column\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        X_ = X.copy()\n",
        "        X_[self.text_column] = X_[self.text_column].apply(lambda x: remove_punctuation(x))\n",
        "        return X_"
      ],
      "metadata": {
        "id": "o4ZIh0IG2z1Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(text):\n",
        "  #remove uupercase\n",
        "  lower_text = text.lower()\n",
        "  #Tokenize\n",
        "  tokenized_text = nltk.word_tokenize(lower_text)\n",
        "  return tokenized_text"
      ],
      "metadata": {
        "id": "g_-L-5Zb5WTt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenizerTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, text_column):\n",
        "        self.text_column = text_column\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        X_ = X.copy()\n",
        "        X_[self.text_column] = X_[self.text_column].apply(lambda x: tokenizer(x))\n",
        "        return X_  "
      ],
      "metadata": {
        "id": "DsF1BPv520rx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "id": "PDex5mpD6AiE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "  without_stopwords = [word for word in text if word not in stopwords]\n",
        "  return  without_stopwords"
      ],
      "metadata": {
        "id": "mP5Srjyr5j9j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RemoveStopwordsTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, text_column):\n",
        "        self.text_column = text_column\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        X_ = X.copy()\n",
        "        X_[self.text_column] = X_[self.text_column].apply(lambda x: remove_stopwords(x))\n",
        "        return X_  "
      ],
      "metadata": {
        "id": "11VKN4pX25JV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_shorttokens(text):\n",
        "  without_shorttokens = [word for word in text if len(word)>2]\n",
        "  return  without_shorttokens"
      ],
      "metadata": {
        "id": "VmHB52Kx6GoB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RemoveShortTokensTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, text_column):\n",
        "        self.text_column = text_column\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        X_ = X.copy()\n",
        "        X_[self.text_column] = X_[self.text_column].apply(lambda x: remove_shorttokens(x))\n",
        "        return X_    "
      ],
      "metadata": {
        "id": "rw3zkcO-26C3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = nltk.PorterStemmer()"
      ],
      "metadata": {
        "id": "gDrS_ph26K9g"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(text):\n",
        "  stemmed_words = [stemmer.stem(word) for word in text]\n",
        "  return stemmed_words"
      ],
      "metadata": {
        "id": "IQNb_nrQ6MRg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StemmingTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, text_column):\n",
        "        self.text_column = text_column\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        X_ = X.copy()\n",
        "        X_[self.text_column] = X_[self.text_column].apply(lambda x: stemming(x))\n",
        "        return X_"
      ],
      "metadata": {
        "id": "UjIpnpHD28tU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class  ReturnStringTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, text_column):\n",
        "        self.text_column = text_column\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        X_ = X.copy()\n",
        "        X_[self.text_column] = X_[self.text_column].apply(lambda x: \" \".join(x))\n",
        "        X_ = pd.Series(X_[self.text_column])\n",
        "        return X_"
      ],
      "metadata": {
        "id": "DT8xiPje2-4_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b8neG6ZmyPQz"
      },
      "outputs": [],
      "source": [
        "pickled_model = pickle.load(open('model.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = pd.DataFrame({'text': [\"FUCK YOU\",\n",
        "                               \"Barely 24 hours ago he said what special and loved people these terrorists were, and how he felt the same way they do.\",\n",
        "                               \"You incited this attack. You own it. Go to hell.\", \n",
        "                               \"Every single illegal immigrant should be dropped from welfare programs, immediately. Absolutely absurd that Americans are on a 5 year waitlist, while Mr. & Mrs. hopped-the-border are helping themselves to our tax dollars. No. No. And NO.\",\n",
        "                               \"You will forever be the winner & the greatest man this country has ever known. We will always be in your debt and owe you endless gratitude. I love you man and you gonna be my spirit animal forever!\",\n",
        "                               \"When you worship a mad man it should tell you some about yourself.  I pray you don't have children\",\n",
        "                               \"That is terrifying. I can’t imagine living with tornadoes.\",\n",
        "                               \"Prayers for the families who lost loved ones.\",\n",
        "                               \"Normally when people are on hallucinogenic,s, I,m couries to try the experience. But gurl-you are on a life long bad trip honey. Ain,t no one want what you havin!\"]})\n",
        "X_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "17INHeda4lNc",
        "outputId": "5da9ad6f-3d5a-45c4-95d0-f935761767b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0                                           FUCK YOU\n",
              "1  Barely 24 hours ago he said what special and l...\n",
              "2   You incited this attack. You own it. Go to hell.\n",
              "3  Every single illegal immigrant should be dropp...\n",
              "4  You will forever be the winner & the greatest ...\n",
              "5  When you worship a mad man it should tell you ...\n",
              "6  That is terrifying. I can’t imagine living wit...\n",
              "7      Prayers for the families who lost loved ones.\n",
              "8  Normally when people are on hallucinogenic,s, ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86bddd1e-fe89-4660-ad0a-c333e1c224e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FUCK YOU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Barely 24 hours ago he said what special and l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You incited this attack. You own it. Go to hell.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Every single illegal immigrant should be dropp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You will forever be the winner &amp; the greatest ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>When you worship a mad man it should tell you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>That is terrifying. I can’t imagine living wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Prayers for the families who lost loved ones.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Normally when people are on hallucinogenic,s, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86bddd1e-fe89-4660-ad0a-c333e1c224e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86bddd1e-fe89-4660-ad0a-c333e1c224e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86bddd1e-fe89-4660-ad0a-c333e1c224e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickled_model.predict(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hILbK7Zr4oOv",
        "outputId": "be11e347-cdee-42d6-fb48-097f39dae527"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}